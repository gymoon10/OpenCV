{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb5c7b81",
   "metadata": {},
   "source": [
    "## 기하학적 변환"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "85322085",
   "metadata": {},
   "source": [
    "영상을 구성하는 픽셀의 배치 구조를 변경하여 전체 영상의 모영을 변환 (픽셀값에 주목). 영상의 밝기 및 명암비 조절, 필터링 등이 픽셀 위치를 고정하고 픽셀 값을 변경한 것과 달리, 기하학적 변환은 **픽셀 값은 그대로 유지한면서 위치를 변경**\n",
    "\n",
    "입력 영상에서 (x, y) 좌표의 픽셀을 결과 영상의 (x', y')좌표로 변환하는 방법을 고유한 함수로 표현\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "* f1, f2를 어떻게 정의하는지에 따라 영상의 크기를 변경할 수도, 영상을 회전시킬 수도 있음\n",
    "\n",
    "ex) Image registration, removal of geometric distortion "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2376cd02",
   "metadata": {},
   "source": [
    "## 1. 어파인 변환\n",
    "\n",
    "영상의 평행이동, 회전, 크기 변환, 전단 변환 등을 통칭\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/44194558/136727805-4e5ea790-4e55-4e1a-b48f-3331d3368ea4.png)\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "다음과 같이 행렬을 이용하여 하나의 **행렬 곱셈 형태**로 표현함\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/44194558/136727827-f419d185-062b-4db4-8e6b-fcd32c9f5dc9.png)\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/44194558/136727838-1108b42d-a0e5-4587-9d61-416e243baaf6.png)\n",
    "\n",
    "  * 2x3 행렬이 어파인 변환 행렬 (실수형)\n",
    "  \n",
    "<br/>\n",
    "<br/>\n",
    "  \n",
    "  \n",
    "최소 3 점의 이동 관계를 알면 입력 영상을 어파인 변환 결과 영상으로 변환시키는 어파인 변환 행렬을 구할 수 있음\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/44194558/136727849-6fb495e8-c736-4708-ae58-8bfbb17aab3d.png)\n",
    "\n",
    " * 점 하나의 이동 관계로부터 x, y좌표에 대한 변환 수식 2개를 얻을 수 있음\n",
    " * 점 3개의 이동 관계로부터 총 6개의 방정식을 구함\n",
    " * 마지막 점은 자동으로 결정됨 (어파인 변환에 의해 직사각형 영상이 평행사변형으로 변환된다는 결과를 알고 있기 때문)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7994c8",
   "metadata": {},
   "source": [
    "#### 어파인 변환 코드\n",
    "\n",
    "cv2.warpAffine(src, M, dsize, dst=None, flags=None, borderMode=None, borderValue=None) -> dst\n",
    "\n",
    "* M : 어파인 변환 행렬. 실수형\n",
    "* dsize : 출력 영상의 크기 지정. (w, h) 튜플, (0, 0)이면 src와 같은 크기\n",
    "* flags : interpolation. default = cv2.INTER_LINEAR\n",
    "* borderValue : 변환으로인해 새롭게 생겨나는 공간을 어떤식으로 채울지 결정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565e8fed",
   "metadata": {},
   "source": [
    "### 이동 변환"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce0b0758",
   "metadata": {},
   "source": [
    "x, y 축 방향으로 얼마나 이동하는 지 변위를 지정\n",
    "\n",
    "가로, 세로 방향으로 영상을 특정 크기만큼 이동시키는 변환 (shift 연산)\n",
    "\n",
    "행렬에 대한 곱셈 수식 하나로 표현하는 것이 효율적 (어파인 변환 행렬 => numpy.ndarray)\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/44194558/136727870-4ca126a6-5c96-4505-8dfc-15405938f8ab.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d16d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "src = cv2.imread('C:/Users/ky_moon/Desktop/vision/ch05/tekapo.bmp')\n",
    "\n",
    "if src is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "aff = np.array([[1, 0, 200],\n",
    "                [0, 1, 100]], dtype=np.float32)  # x축으로 200, y축으로 100\n",
    "\n",
    "dst = cv2.warpAffine(src, aff, (0, 0))\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('dst', dst)  # 입력 영상의 픽셀값이 복사되지 않은 부분은 검은색으로 채워짐\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f543fe25",
   "metadata": {},
   "source": [
    "### 전단 변환 (Shear Transformation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d4cb14e",
   "metadata": {},
   "source": [
    "층 밀림 변환. x, y축 방향에 대해 따로 정의\n",
    "\n",
    "직사각형 형태의 영상을 한 쪽으로 밀어서 평행사편형 모양으로 변환\n",
    "\n",
    "**scaling factor m**을 지정해서 밀림의 정도를 결정함\n",
    "\n",
    "영상의 픽셀을 가로/세로 방향으로 이동시키지만, **픽셀이 어느 위치에 있는가에 따라 이동 정도가 달라짐** (원점은 이동하지 않음)\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/44194558/136727899-e045a9a2-66a7-4e42-8c85-74ca453ace20.png)\n",
    "\n",
    "  1. y 좌표가 증가함에 따라 영상을 가로 방향으로 조금씩 밀음\n",
    "  2. x 좌표가 증가함에 따라 영상을 세로 방향으로 조금씩 밀음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0fc5902",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "src = cv2.imread('C:/Users/ky_moon/Desktop/vision/ch05/tekapo.bmp')\n",
    "\n",
    "if src is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "aff = np.array([[1, 0.5, 0],\n",
    "                [0, 1, 0]], dtype=np.float32)\n",
    "\n",
    "h, w = src.shape[:2]\n",
    "dst = cv2.warpAffine(src, aff, (w + int(h * 0.5), h))  # 반드시 실수값을 갖도록해야함\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('dst', dst)  \n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b017838f",
   "metadata": {},
   "source": [
    "## 2. 영상의 확대와 축소"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfefda1",
   "metadata": {},
   "source": [
    "### 크기 변환 (Scale Transformation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a3b915c2",
   "metadata": {},
   "source": [
    "영상의 전체적 크기를 확대/축소하는 변환. 컴퓨터 비전 프로그래밍에서 매우 자주 발생하는 작업.\n",
    " * 몇 몇 영상 인식 시스템은 정해진 크기의 영상만을 입력으로 받음\n",
    " * 복잡한 알고리즘을 수행하기에 앞서 연산 시간을 단축하기 위해 영상의 크기를 줄임\n",
    "\n",
    "x축, y축 방향으로의 스케일 비율(scale factor)을 지정\n",
    "\n",
    "<br/>\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/44194558/136727918-ffef3036-809b-49e7-905f-08b275b31f50.png)\n",
    "\n",
    "* 원본은 w x h, 결과 영상은 w' x h'크기\n",
    "\n",
    "* 가로 방향으로의 크기 변환 비율 Sx는 w' / w 수식으로 계산, 세로 방향으로의 크기 변환 비율 Sy는 h' / h\n",
    "\n",
    "* Sx/Sy가 1보다 크면 영상이 확대, 작으면 축소"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d663247",
   "metadata": {},
   "source": [
    "#### 크기 변환 코드\n",
    "\n",
    "실제 영상 처리 시스템에서 빈번하게 표현되기 때문에 위처럼 어파인 변환 행렬을 정의하기 보다는 간단하게 크기를 변경할 수 있는 resize 함수를 이용함\n",
    "\n",
    "cv2.resize(src, dsize, dst=None, fx=None, fy=None, interpolation=None) -> dst\n",
    "\n",
    "* dsize : (0, 0)이면 fx, fy의 값을 이용하여 결정\n",
    "* fx, fy : 스케일 비율 (dsize값이 0일때 유효) \n",
    "  * 둘 중 하나는 반드시 지정해줘야 함\n",
    "* interpolation : default = cv2.INTER_LINEAR, 결과 영상의 퀄리티에 영향을 끼침\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/44194558/136727939-bbd0003f-4f44-447f-b7ba-2cf35ac939bf.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f702ac53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "src = cv2.imread('C:/Users/ky_moon/Desktop/vision/ch05/rose.bmp') # src.shape=(320, 480)\n",
    "\n",
    "if src is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "dst1 = cv2.resize(src, (0, 0), fx=4, fy=4, interpolation=cv2.INTER_NEAREST)  # fx, fy에 의해 자동으로 dsize 결정\n",
    "dst2 = cv2.resize(src, (1920, 1280))  # cv2.INTER_LINEAR, dsize 직접 지정 (fx, fy 지정 x)\n",
    "dst3 = cv2.resize(src, (1920, 1280), interpolation=cv2.INTER_CUBIC)  # 3차 회선 보간법 이용\n",
    "dst4 = cv2.resize(src, (1920, 1280), interpolation=cv2.INTER_LANCZOS4)  #\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('dst1', dst1[500:900, 400:800])\n",
    "cv2.imshow('dst2', dst2[500:900, 400:800])\n",
    "cv2.imshow('dst3', dst3[500:900, 400:800])\n",
    "cv2.imshow('dst4', dst4[500:900, 400:800])\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93d8cd62",
   "metadata": {},
   "source": [
    "**영상을 축소할시 디테일이 사라지는 경우가 발생할 수 있음** (특히 한번에 작은 사이즈로 축소시키는 경우 두드러짐)\n",
    "\n",
    "입력 영상을 부드럽게 필터링한 후 축소 or 다단계 축소, INTER_AREA 보간법 권장\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/44194558/136727972-fcdb81ee-3d38-4dc8-be7c-575289be5831.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c08aa6",
   "metadata": {},
   "source": [
    "## 3. 영상의 대칭"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5284f5b",
   "metadata": {},
   "source": [
    "### 대칭 변환 (filp, reflection)\n",
    "\n",
    "입력 영상과 같은 크기의 결과 영상을 반환\n",
    "\n",
    "입력 영상의 픽셀과 결과 영상의 픽셀이 일대일로 대응되기 때문에 보간법이 필요 x\n",
    "\n",
    "<br/>\n",
    "\n",
    "좌우 대칭 변환에 의한 좌표 변환 수식\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/44194558/136727995-8e37491b-55c3-42ac-8fe7-ed01a09f7ffc.png)\n",
    "\n",
    "원본 영상을 x축 방향으로 -1배 크기 변환한 후, x축 방향으로 w-1만큼 이동변환 (어파인 변환의 일종임)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09a3be3",
   "metadata": {},
   "source": [
    "#### 대칭 변환 코드\n",
    "\n",
    "cv2.flip(src, flipCode, dst=None) -> dst\n",
    "\n",
    "* flipCode : 대칭 방향 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efa285e",
   "metadata": {},
   "source": [
    "### 이미지 피라미드"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1acf4300",
   "metadata": {},
   "source": [
    "이미지의 **스케일과 해상도를 조절**하는 작업으로 동일한 이미지를 가지고 여러 다양한 크기로 조절하여 작업. **하나의 영상에 대해 다양한 해상도/스케일의 영상 세트 구성**. 보통 가우시안 블러링 & 다운 샘플링 형태로 구성함\n",
    "\n",
    "\n",
    "Ex)\n",
    "**이미지를 여러 스케일에 걸쳐서 분석**하는 가장 기본적인 방법으로 입력 이미지의 크기를 단계적으로 축소(변화)시켜 가며 필요한 분석 작업을 수행. 이때 이렇게 생성된 일련의 이미지 집합이 이미지 피라미드\n",
    "\n",
    "확보한 얼굴 이미지에서의 얼굴 크기와 다른 이미지에서 보이는 얼굴 크기가 다를 수 있기 때문에 **탐색 대상 이미지의 해상도를 다단계로** 만들어 각 단계에서 얼굴을 탐색. 특정 해상도에서 검출되지 않는 특징을 다른 해상도에서는 쉽게 감지할 수도 있음.\n",
    "\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/44194558/136728019-2b57ef49-f771-4234-b675-fbf7fac7bb05.png)\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/44194558/136728032-e70d5832-9b34-4686-b01e-1be9b707e951.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa9a411",
   "metadata": {},
   "source": [
    "#### 영상 피라미드 다운 샘플링 코드\n",
    "\n",
    "cv2.pyrDown(src, dst=None, dstsize=None, borderType=None) -> dst\n",
    "\n",
    "* dstsize : 출력 영상 크기, default : 입력 영상의 가로, 세로 크기의 1/2\n",
    "* 5x5 크기의 가우시안 필터를 적용하고, 이후에 짝수 행과 열을 제거하여 작은 크기의 영상을 생성함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db24e858",
   "metadata": {},
   "source": [
    "#### 영상 피라미드 업샘플링 코드\n",
    "\n",
    "cv2.pyrUp(src, dst=None, dstsize=None, borderType=None) -> dst\n",
    "\n",
    "* dstsize : 출력 영상 크기, default : 입력 영상의 가로, 세로 크기의 2배"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9556dd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "src = cv2.imread('C:/Users/ky_moon/Desktop/vision/ch05/cat.bmp')\n",
    "\n",
    "if src is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "rc = (250, 120, 200, 200)  # rectangle tuple (x, y, w, h)\n",
    "\n",
    "# 원본 영상에 그리기\n",
    "cpy = src.copy()\n",
    "cv2.rectangle(cpy, rc, (0, 0, 255), 2)\n",
    "cv2.imshow('src', cpy)\n",
    "cv2.waitKey()\n",
    "\n",
    "# 피라미드 영상에 그리기\n",
    "for i in range(1, 4):\n",
    "    src = cv2.pyrDown(src)  # 다운 샘플링\n",
    "    cpy = src.copy()\n",
    "    cv2.rectangle(cpy, rc, (0, 0, 255), 2, shift=i)  # shift : 그리기 좌표값의 축소 비율, 입력 영상의 크기가 줄어들어도 정상적으로 고양이 얼굴에 사각형을 그림\n",
    "    cv2.imshow('src', cpy)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyWindow('src')\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de96ffe9",
   "metadata": {},
   "source": [
    "## 4. 영상의 회전"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0096bc65",
   "metadata": {},
   "source": [
    "### 회전 변환\n",
    "\n",
    "특정 좌표를 기준으로 영상을 특정 각도만큼 반시계 방향으로 회전시키는 변환\n",
    "\n",
    "Ex) 문서 인식 OCR 시스템의 경우, 글씨 영상의 수평이 맞아야 인식률이 증가하기 때문에 문서의 회전각도를 측정하여 영상을 적절하게 회전변환 시킨 후 시스템의 입력으로 사용함\n",
    "\n",
    "<br/>\n",
    "\n",
    "원점을 기준으로 영상을 반시계 방향으로 theta만큼 회전하는 변환\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/44194558/136728058-b90589ef-f7b2-47a5-8222-d25804228fef.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead7642f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "src = cv2.imread('C:/Users/ky_moon/Desktop/vision/ch05/tekapo.bmp')\n",
    "\n",
    "if src is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "rad = 20 * math.pi / 180  # theta(20도를 radian 단위로, 반시계 방향)\n",
    "aff = np.array([[math.cos(rad), math.sin(rad), 0],\n",
    "                [-math.sin(rad), math.cos(rad), 0]], dtype=np.float32)  # 어파인 행렬 지정\n",
    "\n",
    "dst = cv2.warpAffine(src, aff, (0, 0))\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75750595",
   "metadata": {},
   "source": [
    "#### 회전 변환 행렬 코드\n",
    "\n",
    "cv2.getRotationMatrix2D(center, anlge, scale) -> retval\n",
    "\n",
    "* center : 회전 중심 좌표 (x, y)튜플\n",
    "* angle : 반시계 방향 회전 각도(degree). 음수면 시계 방향\n",
    "* scale : 추가적인 확대 비율\n",
    "* retval : 2 x 3 어파인 변환 실수형 행렬.\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/44194558/136728074-4fc6c7e9-22c5-4b1e-8cf7-d2596c2cc5c3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9658c3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "src = cv2.imread('C:/Users/ky_moon/Desktop/vision/ch05/tekapo.bmp')\n",
    "\n",
    "if src is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "cp = (src.shape[1] / 2, src.shape[0] / 2)  # 영상의 중앙을 기준으로 회전함\n",
    "rot = cv2.getRotationMatrix2D(cp, 20, 1)  # 회전 변환 행렬(반시계 방향으로 20도 회전, scaling x)\n",
    "\n",
    "dst = cv2.warpAffine(src, rot, (0, 0))  # 원본 영상에 어파인 회전 변환 적용\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()ㅡ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "396b7122",
   "metadata": {},
   "source": [
    "## 5. 투시 변환\n",
    "\n",
    "어파인 변환보다 자유도가 높은 변환 (perspective transform)\n",
    "\n",
    "직사각형 형태의 영상을 **임의의 볼록 사각형 형태로 변경** (두 직선의 평행 관계가 깨질 수 있음)\n",
    "\n",
    "<br/>\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/44194558/136728123-fa2fb290-519c-44bf-8235-b55677ccbedd.png)\n",
    "\n",
    "<br/>\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/44194558/136728095-90587c79-377d-4ab5-8991-2178772518f8.png)\n",
    "  * DOF : degree of freedom (방정식의 파라미터 개수)\n",
    "  * 투시 변환은 직선들의 평행관계가 유지되지 않기 때문에 임의의 사각형 형태로 나타남\n",
    "  * 점 4개의 이동 관계로부터 8개의 방정식을 얻음"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c4b6cf84",
   "metadata": {},
   "source": [
    "동차 좌표계 (homogeneous coordinates) - 좌표 계산 편의를 위해 사용\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/44194558/136728157-7eb51993-33bb-40d1-b129-ce0594eba868.png)\n",
    "\n",
    " * w : 결과 영상의 좌표를 표현할 때 사용되는 비례 상수\n",
    "\n",
    "<br/>\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/44194558/136728173-7d08d319-234a-4c64-a3d1-0f49bd1a52d9.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf353a7f",
   "metadata": {},
   "source": [
    "#### 어파인 변환 행렬 코드\n",
    "\n",
    "cv2.getAffineTransform(src, dst) -> retval\n",
    "\n",
    "* src : 3개의 원본 좌표점. numpy.ndarray.shape=(3, 2)   ex) np.array([[x1, y1], [x2, y2], [x3, y3]], np.float32)\n",
    "* dst : 3개의 결과 좌표점\n",
    "* retval : **2 x 3** 투시 변환 행렬\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/44194558/136728192-13645642-3fdf-469b-aa7a-a69980919628.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1ff772",
   "metadata": {},
   "source": [
    "#### 어파인 변환 코드\n",
    "\n",
    "cv2.warpAffine(src, M, dsize, dst=None, flags=None, borderMode=None, borderValue=None) -> dst\n",
    "\n",
    "* src : 입력 영상\n",
    "* M : 2 x 3 어파인 변환 행렬. 실수형.\n",
    "* dsize : 결과 영상의 크기. (w, h)튜플. (0, 0)이면 src와 같은 크기\n",
    "* dst : 출력\n",
    "* flags : 보간법. default=cv2.INTER_LINEAR\n",
    "* borderMode : 가장자리 픽셀 확장 방식. default=cv2.BORDER_CONSTANT\n",
    "* borderValue : cv2.BORDER_CONSTANT일 때 사용하는 상수 값. default=0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a631eb82",
   "metadata": {},
   "source": [
    "#### 투시 변환 행렬 코드\n",
    "\n",
    "cv2.getPerspectiveTransform(src, dst, solveMethod=None) -> retval\n",
    "\n",
    "* src : 4개의 원본 좌표점. numpy.ndarray.shape=(4, 2)\n",
    "* dst : 4개의 결과 좌표점\n",
    "* retval : **3 x 3** 투시 변환 행렬\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/44194558/136728214-393fa9cd-c9ab-4097-bf84-e7bc3f7e20d9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6f3879",
   "metadata": {},
   "source": [
    "#### 투시 변환 코드\n",
    "\n",
    "cv2.warpPerspective(src, M, dsize, dst=None, flags=None, borderMode=None, borderValue=None) -> dst\n",
    "\n",
    "* M : 3 x 3 투시 변환 실수형 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b40a490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 찌그러진 명함 펴기\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "src = cv2.imread('C:/Users/ky_moon/Desktop/vision/ch05/namecard.jpg')\n",
    "\n",
    "if src is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "w, h = 720, 400  # 출력 영상의 크기 지정 (가로 세로 9:5 비율)\n",
    "srcQuad = np.array([[325, 307], [760, 369], [718, 611], [231, 515]], np.float32)  # 명함의 꼭지점 좌표 (좌측 상단부터 시계 방향으로)\n",
    "dstQuad = np.array([[0, 0], [w-1, 0], [w-1, h-1], [0, h-1]], np.float32)\n",
    "\n",
    "pers = cv2.getPerspectiveTransform(srcQuad, dstQuad)  # 4개 점의 이동 관계로부터 투시 변환 행렬 구하기, 점들이 투시 변환에 의해 어느 위치로 이동하는지\n",
    "dst = cv2.warpPerspective(src, pers, (w, h))  # 실제 영상을 (w, h) 크기의 결과 영상으로 투시 변환\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c60dfa2",
   "metadata": {},
   "source": [
    "![image](https://user-images.githubusercontent.com/44194558/136728231-26e651c0-ab15-4934-a2f6-ec08ce5f74a8.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "642d3d83",
   "metadata": {},
   "source": [
    "## 6. 리매핑\n",
    "\n",
    "영상의 **특정 위치 픽셀을 다른 위치에 재배치**. **규칙성 없이** 마음대로 이미지의 모양을 변환하기 때문에 자유도 있는 변화가 가능 (입력 영상을 직선이 아닌 곡선으로 표현할 수 있음)\n",
    "\n",
    "기하학적 변환을 mapping. **출력 영상의 좌표를 입력 영상의 어느 좌표를 참조해서 가지고 올 것인지를 설정**하여 출력 영상의 모든 픽셀 값을 셋팅해 출력 영상을 만듬. **출력 영상의 x, y 좌표에서 입력 영상의 어느 위치를 참조할 것인지를 나타내는 map x, map y 함수를 정의**.\n",
    "\n",
    "\n",
    "어파인, 투시 변환을 포함한 다양한 변환을 리매핑으로 표현 가능\n",
    "\n",
    "dst(x, y) = src(map_x(x, y), map_y(x, y))\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/44194558/136728256-48c39d92-adee-4869-b9b4-76c64114258a.png)\n",
    "\n",
    "  * 대칭 변환 : x 좌표를 (가로 크기-1-x)로 mapping, y는 그대로\n",
    "  * 이동 변환 : (x-200)은 입력 영상의 좌표가 x 방향으로(오른쪽으로) 200 이동한다는 의미 (-200 만큼 이동 x), 아래 방향으로는 100 이동"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d851ec70",
   "metadata": {},
   "source": [
    "#### 리매핑 코드 \n",
    "\n",
    "cv2.remap(src, map1, map2, interpolation, dst=None, borderMode=None, borderValue=None) -> dst\n",
    "\n",
    "* src : 입력 영상\n",
    "* map1 : 결과 영상의 (x, y) 좌표가 참조할 입력 영상의 x 좌표\n",
    "* map2 : 결과 영상의 (x, y) 좌표가 참조할 입력 영상의 y 좌표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11b014d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "src = cv2.imread('C:/Users/ky_moon/Desktop/vision/ch05/tekapo.bmp')\n",
    "\n",
    "if src is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "h, w = src.shape[:2]\n",
    "\n",
    "map2, map1 = np.indices((h, w), dtype=np.float32)  # np.indice는 행렬의 인덱스값 반환. y좌표값, x좌표값을 따로따로 행렬의 형태로 변환\n",
    "\n",
    "# x 좌표에 sin함수를 사용하여 파도처럼 요동치게 만듬 (위아래로 10 픽셀 만큼 요동치게)\n",
    "map2 = map2 + 10 * np.sin(map1 / 32)  \n",
    "\n",
    "dst = cv2.remap(src, map1, map2, cv2.INTER_CUBIC, borderMode=cv2.BORDER_DEFAULT)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a85f3fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리매핑 이전 x 좌표값 : [[  0.   1.   2. ... 637. 638. 639.]\n",
      " [  0.   1.   2. ... 637. 638. 639.]\n",
      " [  0.   1.   2. ... 637. 638. 639.]\n",
      " [  0.   1.   2. ... 637. 638. 639.]\n",
      " [  0.   1.   2. ... 637. 638. 639.]]\n",
      "리매핑 이전 y 좌표값 : [[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 1. 1. 1.]\n",
      " [2. 2. 2. ... 2. 2. 2.]\n",
      " [3. 3. 3. ... 3. 3. 3.]\n",
      " [4. 4. 4. ... 4. 4. 4.]]\n"
     ]
    }
   ],
   "source": [
    "map2, map1 = np.indices((h, w), dtype=np.float32)  # 입력 영상의 y, x 좌표값\n",
    "print('리매핑 이전 x 좌표값 :', map1[:5])\n",
    "print('리매핑 이전 y 좌표값 :', map2[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c633fa88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리매핑 이후 x 좌표값 : [[  0.   1.   2. ... 637. 638. 639.]\n",
      " [  0.   1.   2. ... 637. 638. 639.]\n",
      " [  0.   1.   2. ... 637. 638. 639.]\n",
      " [  0.   1.   2. ... 637. 638. 639.]\n",
      " [  0.   1.   2. ... 637. 638. 639.]]\n",
      "리매핑 이후 y 좌표값 : [[ 0.          0.31244913  0.62459314 ...  8.707346    8.856742\n",
      "   8.99749   ]\n",
      " [ 1.          1.3124491   1.6245931  ...  9.707346    9.856742\n",
      "   9.99749   ]\n",
      " [ 2.          2.3124492   2.6245933  ... 10.707346   10.856742\n",
      "  10.99749   ]\n",
      " [ 3.          3.3124492   3.6245933  ... 11.707346   11.856742\n",
      "  11.99749   ]\n",
      " [ 4.          4.312449    4.6245933  ... 12.707346   12.856742\n",
      "  12.99749   ]]\n"
     ]
    }
   ],
   "source": [
    "map2 = map2 + 10 * np.sin(map1 / 32)  # y 좌표가 사인 함수 값을 더함\n",
    "print('리매핑 이후 x 좌표값 :', map1[:5])\n",
    "print('리매핑 이후 y 좌표값 :', map2[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0f02dce",
   "metadata": {},
   "source": [
    "![image](https://user-images.githubusercontent.com/44194558/136728274-e808ab3b-bff8-46dc-bbc1-ff17ca374987.png)\n",
    "\n",
    "일종의 meshgrid 형태"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d83ce1c",
   "metadata": {},
   "source": [
    "## 문서 스캐너\n",
    "\n",
    "1. 마우스로 문서 모서리를 선택하고 이동\n",
    "\n",
    "2. 키보드 enter키 인식\n",
    "\n",
    "3. 문서 영상을 직사각형 형태로 똑바로 펴기 (투시 변환)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b6947d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "def drawROI(img, corners):\n",
    "    cpy = img.copy()\n",
    "    \n",
    "    # 색 지정\n",
    "    c1 = (192, 192, 255)\n",
    "    c2 = (128, 128, 255)\n",
    "    \n",
    "    # 4개의 점에 대해 반지름 25의 핑크색 원을 그림(원 내부를 색깔로 채움)\n",
    "    for pt in corners:  \n",
    "        cv2.circle(cpy, tuple(pt), 25, c1, -1, cv2.LINE_AA)\n",
    "    \n",
    "    # 선택된 4개의 모서리점을 잇는 직선 4개를 그려 사각형을 표현\n",
    "    # 점들의 좌표가 ndarray 형식이기 때문에 tuple로 변환해주어야 함\n",
    "    cv2.line(cpy, tuple(corners[0]), tuple(corners[1]), c2, 2, cv2.LINE_AA)  \n",
    "    cv2.line(cpy, tuple(corners[1]), tuple(corners[2]), c2, 2, cv2.LINE_AA)\n",
    "    cv2.line(cpy, tuple(corners[2]), tuple(corners[3]), c2, 2, cv2.LINE_AA)\n",
    "    cv2.line(cpy, tuple(corners[3]), tuple(corners[0]), c2, 2, cv2.LINE_AA)\n",
    "    \n",
    "    # 원본 이미지와 그림을 그려놓은 이미지를 3:7 비율로 합성\n",
    "    disp = cv2.addWeighted(img, 0.3, cpy, 0.7, 0) # 전체 픽셀에 대한 연산이라 시간이 걸릴 수 있음\n",
    "\n",
    "    return disp\n",
    "\n",
    "\n",
    "def onMouse(event, x, y, flags, param):  \n",
    "    global srcQuad, dragSrc, ptOld, src\n",
    "    \n",
    "    # 마우스가 눌려져 있을 때\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        for i in range(4):\n",
    "            # 클릭한 부분(x, y)이 4개 모서리점의 원 안에 들어가 있는 지 판별\n",
    "            if cv2.norm(srcQuad[i] - (x, y)) < 25: # 클릭한 부분이 특정 모서리점의 원 안에 포함되어 있을 때만 드래그가 가능하도록\n",
    "                dragSrc[i] = True  # 드래그 시작\n",
    "                ptOld = (x, y)  # 마우스를 움직일 때 마다 원이 이동할 수 있도록 (이동하는 변위를 알기 위해 재사용)\n",
    "                break\n",
    "    \n",
    "    # 드래그가 끝나면 False로 초기화\n",
    "    if event == cv2.EVENT_LBUTTONUP:\n",
    "        for i in range(4):\n",
    "            dragSrc[i] = False\n",
    "    \n",
    "    # mousemove를 마우스가 눌려져 있을때만 체크\n",
    "    if event == cv2.EVENT_MOUSEMOVE:\n",
    "        for i in range(4):\n",
    "            \n",
    "            # 어떤 점을 드래그하고 있으면\n",
    "            if dragSrc[i]:\n",
    "                dx = x - ptOld[0]  # 현재 좌표 - 이전 좌표 (이동하는 변위)\n",
    "                dy = y - ptOld[1]\n",
    "\n",
    "                srcQuad[i] += (dx, dy)  # 이동\n",
    "\n",
    "                cpy = drawROI(src, srcQuad) # 이동할때 마다 화면에 반영\n",
    "                cv2.imshow('img', cpy)\n",
    "                ptOld = (x, y)  # 현재 점으로 세팅\n",
    "                break\n",
    "\n",
    "\n",
    "# 입력 이미지 불러오기\n",
    "src = cv2.imread('C:/Users/ky_moon/Desktop/vision/ch05/scanned.jpg')\n",
    "\n",
    "if src is None:\n",
    "    print('Image open failed!')\n",
    "    sys.exit()\n",
    "\n",
    "# 입력 영상 크기 및 출력 영상 크기\n",
    "h, w = src.shape[:2]\n",
    "\n",
    "# 문서를 똑바로 편 이미지의 가로, 세로 크기\n",
    "dw = 500\n",
    "dh = round(dw * 297 / 210)  # A4 용지 크기: 210x297cm\n",
    "\n",
    "# 모서리 점들의 좌표(반시계 방향), 드래그 상태 여부\n",
    "# 선택하려고하는 모서리점 4개의 점을 저장, 마우스 이벤트를 처리하면 변경\n",
    "srcQuad = np.array([[30, 30], [30, h-30], [w-30, h-30], [w-30, 30]], np.float32)  # 초기치(선택 하려는 포인트가 영상 끝 모서리에 위치하지 않게)\n",
    "\n",
    "# 출력 영상의 모서리 위치 지정\n",
    "dstQuad = np.array([[0, 0], [0, dh-1], [dw-1, dh-1], [dw-1, 0]], np.float32)  \n",
    "dragSrc = [False, False, False, False]  # 4개의 점 중 어떤 점을 drag하는 지 상태 정보를 저장\n",
    "\n",
    "# 모서리점, 사각형 그리기\n",
    "# 입력 영상에 선택한 점의 좌표를 전송. display용\n",
    "disp = drawROI(src, srcQuad)\n",
    "\n",
    "cv2.imshow('img', disp)\n",
    "cv2.setMouseCallback('img', onMouse)  \n",
    "\n",
    "while True:\n",
    "    key = cv2.waitKey()\n",
    "    if key == 13:  # ENTER 키\n",
    "        break  # while loop를 빠져 나옴\n",
    "    elif key == 27:  # ESC 키\n",
    "        cv2.destroyWindow('img')\n",
    "        sys.exit()  # 종료\n",
    "\n",
    "# 투시 변환\n",
    "pers = cv2.getPerspectiveTransform(srcQuad, dstQuad)\n",
    "dst = cv2.warpPerspective(src, pers, (dw, dh), flags=cv2.INTER_CUBIC)\n",
    "\n",
    "# 결과 영상 출력\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "735451e8",
   "metadata": {},
   "source": [
    "**초기 화면** \n",
    "\n",
    "선택 영역에 해당하는 원이 ([30, 30], [30, h-30], [w-30, h-30], [w-30, 30]] 위치)\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/44194558/136728294-f290fa61-8a46-40b5-adde-1b23e77f2a2c.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "784fd9de",
   "metadata": {},
   "source": [
    "**결과 영상**\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/44194558/136728313-43795e57-f125-4a0c-8ffa-e9e5abafd73a.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bc5f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
